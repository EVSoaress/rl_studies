{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaxIWENS4SsYDLwvl3Hb/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EVSoaress/rl_studies/blob/main/rl_normalized_advantage_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCZmQKLpBtFQ"
      },
      "source": [
        "## DQN for continuous action spaces: Normalized Advantage Function (NAF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohgRzyBxe_rE"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y xvfb\n",
        "\n",
        "!pip install \\\n",
        "    gym==0.22 \\\n",
        "    gym[box2d] \\\n",
        "    pytorch-lightning==1.6.0 \\\n",
        "    pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display(visible=False, size=(1400, 900)).start()"
      ],
      "metadata": {
        "id": "nhZPT6v8fHYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cP5t6U7-nYoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91bc0e7-8f18-4152-9e56-1ae2729de36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import gym\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque, namedtuple\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import IterableDataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "\n",
        "from gym.wrappers import RecordVideo, RecordEpisodeStatistics, TimeLimit\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "num_gpus = torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z_IrPlU1wwPx"
      },
      "outputs": [],
      "source": [
        "def display_video(episode=0):\n",
        "  video_file = open(f'/content/videos/rl-video-episode-{episode}.mp4', \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"<video width=600 controls><source src='{video_url}'></video>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the Deep Q-Network"
      ],
      "metadata": {
        "id": "BCP_-zTJouC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NafDQN(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, obs_size, action_dims, max_action):\n",
        "    super().__init__()\n",
        "    self.action_dims = action_dims\n",
        "    self.max_action = torch.from_numpy(max_action).to(device)\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(obs_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.linear_mu = nn.Linear(hidden_size, action_dims)\n",
        "    self.linear_value = nn.Linear(hidden_size, 1)\n",
        "    self.linear_matrix = nn.Linear(hidden_size, \n",
        "                                   int(action_dims * (action_dims + 1) / 2))\n",
        "    \n",
        "    #Mu: compute action hightest Q-value\n",
        "\n",
        "\n",
        "    #value: compute value state\n",
        "\n",
        "    #forward: Q-value"
      ],
      "metadata": {
        "id": "Bqi90YEoox_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}